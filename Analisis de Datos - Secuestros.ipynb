{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis de Datos: Conteo de Victimas por Secuestros y Desapariciones Forzadas\n",
    "\n",
    "Dataset: Victimas ([Portal Datos Abiertos - Fiscalia](https://www.datos.gov.co/browse?q=fiscalia%20spoa&sortBy=relevance))\n",
    "\n",
    "### 1. Estructura Datos\n",
    "\n",
    "|Columna|Descripción|Tipo de Caracteristica|Tipo de Dato|\n",
    "|---|---|---|---|\n",
    "|RUPTURA |Indica si el proceso es o no una ruptura procesal. **(1 = Si, 0 = No)**| Categórico | Integer |\n",
    "|CONEXO|Indica si el proceso es o no una conexidad. **(1 = Si, 0 = No)** | Categórico | Integer |\n",
    "|ESTADO_NOTICIA|Estado de la noticia criminal que contenía el delito de referencia al momento de la consulta del dato en el sistema de información **(1 = Activo, 0 = Inactivo)**|Categórico|Integer|\n",
    "|ETAPA|Etapa procesal de la noticia criminal que contenía el delito al momento de la consulta del dato en el sistema de información. **[1.1 Etapas]** |Categórico|string|\n",
    "|ANIO_DENUNCIA|Año en el que se denunció el hecho. |Categórico|String|\n",
    "|ANIO_ENTRADA|Año en que entró a la Fiscalía la noticia criminal.|Categórico|String|\n",
    "|ANIO_HECHO|Año en que presuntamente ocurrió el hecho.|Categórico|String|\n",
    "|LEY|Marco legal en el que se encontraba la noticia criminal al momento de la consulta del dato en el sistema de información **[1.2 Leyes]**|Categórico|String|\n",
    "|PAIS|País en donde presuntamente ocurrieron los hechos que conoció la Fiscalía. **(1 = Nacional, 0 = Extranjero)**|Categórico|Integer|\n",
    "|DEPARTAMENTO|Departamento en donde presuntamente ocurrieron los hechos que conoció la Fiscalía.|Categórico|String|\n",
    "|MUNICIPIO|Municipio en donde presuntamente ocurrieron los hechos que conoció la Fiscalía.|Categórico|String|\n",
    "|SECCIONAL|Dependencia de la Fiscalía con la noticia criminal asignada al momento de la consulta del dato en el sistema de información.|Categórico|String|\n",
    "|DELITO|Descripción del artículo según el Código Penal <br>**Solo importan Secuestros y Desapariciones, como están en datasets separados esta columna se puede eliminar**|Categórico| String |\n",
    "|IMPUTACION|Indica si el caso tiene o no alguna actuación de imputación. **(1 = Si, 0 = No)** | Categórico | Integer |\n",
    "|CONDENA|Indica si el caso tiene o no alguna actuación de condena. **(1 = Si, 0 = No)** | Categórico | Integer |\n",
    "|ATIPICIDAD_INEXISTENCIA|Indica si el caso tiene o no la última actuación de archivo o preclusión por atipicidad o inexistencia **(1 = Si, 0 = No)** | Categórico | Integer |\n",
    "|ACUSACION|Indica si el caso tiene o no alguna actuación de acusación. **(1 = Si, 0 = No)** | Categórico | Integer |\n",
    "|SEXO_VICTIMA|Sexo registrado de la víctima. **(1 = MASCULINO, 0 = FEMENINO, -1 = SIN REGISTRO)** | Categórico | Integer |\n",
    "|GRUPO_EDAD_VICTIMA|Agrupación de edad a la que pertenece la víctima. **[1.4]**|Categórico|String|\n",
    "|PAIS_NACIMIENTO|País de nacimiento registrado para la víctima **(1 = Nacional, 0 = Extranjero)**|Categórico|Integer|\n",
    "|TOTAL_VICTIMAS|Conteo total de víctimas al cruzar las variables anteriores.|Numérico|Integer|\n",
    "|CAPTURA|Indica si el caso tiene o no alguna actuación de captura. **(1 = Si, 0 = No)**| Categórico |Integer|\n",
    "\n",
    "#### 1.1. Etapas\n",
    "\n",
    "- INDAGACIÓN\n",
    "- ETAPA DE INVESTIGACION PRELIMINAR\n",
    "- EJECUCIÓN DE PENAS\n",
    "- ETAPA DE INSTRUCCION\n",
    "- JUICIO\n",
    "- INVESTIGACIÓN\n",
    "- QUERELLABLE\n",
    "- TERMINACIÓN ANTICIPADA\n",
    "- ETAPA JUICIO\n",
    "\n",
    "#### 1.2. Leyes\n",
    "\n",
    "- Ley 600 (rige hasta el 1 de enero del 2005)\n",
    "- Ley 960 (desde 01/01/2005 en adelante)\n",
    "- Ley 1098 de infancia y adolecencia\n",
    "- Jurisdicción de menores (valores presentes en los registros)\n",
    "\n",
    "#### 1.3 Seccionales\n",
    "\n",
    "- DIRECCIÓN SECCIONAL DE MEDELLÍN\n",
    "- DIRECCIÓN SECCIONAL DE VALLE DEL CAUCA\n",
    "- DIRECCIÓN SECCIONAL DE BOYACÁ\n",
    "- DIRECCIÓN SECCIONAL DE CAQUETÁ\n",
    "- DIRECCIÓN SECCIONAL DE ANTIOQUIA\n",
    "- DIRECCIÓN SECCIONAL DE NARIÑO\n",
    "- DIRECCIÓN ESPECIALIZADA CONTRA LAS VIOLACIONES A LOS DERECHOS HUMANOS\n",
    "- DIRECCIÓN SECCIONAL DE CALI\n",
    "- DIRECCION ESPECIALIZADA CONTRA ORGANIZACIONES CRIMINALES\n",
    "- DIRECCIÓN SECCIONAL DE BOGOTÁ\n",
    "- DIRECCIÓN SECCIONAL DE CAUCA\n",
    "- DIRECCIÓN SECCIONAL DE TOLIMA\n",
    "- DIRECCIÓN SECCIONAL DE MAGDALENA\n",
    "- DIRECCIÓN SECCIONAL DE SUCRE\n",
    "- DIRECCIÓN SECCIONAL DE NORTE DE SANTANDER\n",
    "- DIRECCIÓN SECCIONAL DE QUINDÍO\n",
    "- DIRECCIÓN SECCIONAL DE PUTUMAYO\n",
    "- DIRECCIÓN SECCIONAL DE META\n",
    "- DIRECCIÓN SECCIONAL DE LA GUAJIRA\n",
    "- DIRECCIÓN SECCIONAL DE CUNDINAMARCA\n",
    "- DIRECCIÓN SECCIONAL DE SANTANDER\n",
    "- DIRECCIÓN SECCIONAL DE RISARALDA\n",
    "- DIRECCIÓN SECCIONAL DE HUILA\n",
    "- DIRECCIÓN SECCIONAL DE CALDAS\n",
    "- DIRECCIÓN SECCIONAL DE ARAUCA\n",
    "- DIRECCIÓN SECCIONAL DE CHOCÓ\n",
    "- DIRECCIÓN SECCIONAL DE ATLÁNTICO\n",
    "- DIRECCIÓN SECCIONAL DE MAGDALENA MEDIO\n",
    "- DIRECCIÓN SECCIONAL DE BOLÍVAR\n",
    "- DIRECCIÓN SECCIONAL DE CÓRDOBA\n",
    "- DIRECCIÓN SECCIONAL DE CESAR\n",
    "- DIRECCIÓN SECCIONAL DE CASANARE\n",
    "- NIVEL CENTRAL FISCALIAS\n",
    "- DIRECCIÓN SECCIONAL DE GUAVIARE\n",
    "- DIRECCIÓN SECCIONAL DE AMAZONAS\n",
    "- DIRECCIÓN SECCIONAL DE SAN ANDRÉS, PROVIDENCIA Y SANTA CATALINA\n",
    "- DIRECCIÓN SECCIONAL DE VICHADA\n",
    "- DIRECCIÓN SECCIONAL DE GUAINÍA - VAUPÉS\n",
    "- DELEGADA CONTRA LA CRIMINALIDAD ORGANIZADA\n",
    "- DIRECCION ESPECIALIZADA CONTRA EL NARCOTRAFICO\n",
    "- DELEGADA ANTE LA CORTE SUPREMA DE JUSTICIA\n",
    "- DIRECCION ESPECIALIZADA CONTRA LA CORRUPCIÓN\n",
    "- DIRECCION DE JUSTICIA TRANSICIONAL\n",
    "- DELEGADA PARA LA SEGURIDAD CIUDADANA\n",
    "- DIRECCIÓN ESPECIALIZADA CONTRA EL LAVADO DE ACTIVOS\n",
    "\n",
    "#### 1.4 Categorías: Grupo Edad Victima\n",
    "\n",
    "Los rangos entre parentesis se dan a entender dado que no son tan necesarios para caracterizar las categorías\n",
    "\n",
    "- SIN REGISTRO\n",
    "- ADULTEZ (29 - 59)\n",
    "- JUVENTUD (18 - 28)\n",
    "- ADOLESCENTE (14 - 17)\n",
    "- ADULTO MAYOR (MAS DE 60)\n",
    "- PRIMERA INFANCIA (0 - 5)\n",
    "- INFANCIA (6 - 11)\n",
    "- PRE-ADOLESCENTE (12 - 13)\n",
    "\n",
    "### 2. Tratamiento de Datos\n",
    "\n",
    "2.1.  Cada fila del DataFrame representa el suceso y reporta la cantidad de victimas  \n",
    "2.2.  Se debe organizadon los datos de acuerdo a lo expresado en el punto 1  \n",
    "2.3.  Debido a que las columnas categoricas de tensorflow solo reciben un string continuo se toma _ como reemplazo para los espacios  \n",
    "2.4.  Se reemplazan las celdas vacías por -1 en las columnas numericas y por SIN_REGISTRO en las columnas categoricas, POR_ESTABLECER en el caso de los departamentos  \n",
    "2.5.  Las categorias se toman en mayuscula exceptuando los departamentos y/o municipios  \n",
    "\n",
    "\n",
    "### 2.1 Importar los Datos Tratados mediante PANDAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import feature_column\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RUPTURA                     int64\n",
       "CONEXO                      int64\n",
       "ESTADO_NOTICIA              int64\n",
       "ETAPA                      object\n",
       "ANIO_DENUNCIA              object\n",
       "ANIO_HECHO                 object\n",
       "LEY                        object\n",
       "PAIS                        int64\n",
       "DEPARTAMENTO               object\n",
       "MUNICIPIO                  object\n",
       "SECCIONAL                  object\n",
       "IMPUTACION                  int64\n",
       "CONDENA                     int64\n",
       "ATIPICIDAD_INEXISTENCIA     int64\n",
       "ACUSACION                   int64\n",
       "CAPTURA                     int64\n",
       "SEXO_VICTIMA                int64\n",
       "GRUPO_EDAD_VICTIMA         object\n",
       "PAIS_NACIMIENTO             int64\n",
       "TOTAL_VICTIMAS              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dataset Conteo de Víctimas por año y municipio\n",
    "dfSecuestros = pd.read_csv('DataSetSecuestros.csv')\n",
    "dfSecuestros.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dividir el DataFrame en los conjuntos de prueba, validación y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25576 train examples\n",
      "6394 validation examples\n",
      "7993 test examples\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(dfSecuestros, test_size=0.2)\n",
    "train, val = train_test_split(train, test_size=0.2)\n",
    "print(len(train), 'train examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Envolver el DataFrame de pandas con tf.data para poder aplicar feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a tf.data dataset from a Pandas Dataframe\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop('CONDENA')\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tamaño del numero de datos por iteración que se necesitan para entrenar y probar el algoritmo\n",
    "batch_size = 32\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['RUPTURA', 'CONEXO', 'ESTADO_NOTICIA', 'ETAPA', 'ANIO_DENUNCIA', 'ANIO_HECHO', 'LEY', 'PAIS', 'DEPARTAMENTO', 'MUNICIPIO', 'SECCIONAL', 'IMPUTACION', 'ATIPICIDAD_INEXISTENCIA', 'ACUSACION', 'CAPTURA', 'SEXO_VICTIMA', 'GRUPO_EDAD_VICTIMA', 'PAIS_NACIMIENTO', 'TOTAL_VICTIMAS']\n",
      "A batch of TOTAL_VICTIMAS: tf.Tensor([1 1 1 2 1 1 1 1 1 1 1 1 2 1 4 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1], shape=(32,), dtype=int32)\n",
      "A batch of CONDENAS: tf.Tensor([0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for feature_batch, label_batch in train_ds.take(1):\n",
    "    print('Every feature:', list(feature_batch.keys()))\n",
    "    print('A batch of TOTAL_VICTIMAS:', feature_batch['TOTAL_VICTIMAS'])\n",
    "    print('A batch of CONDENAS:', label_batch )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Verificando las columnas de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use this batch to demonstrate several types of feature columns\n",
    "example_batch = next(iter(train_ds))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A utility method to create a feature column\n",
    "# and to transform a batch of data\n",
    "def demo(feature_column):\n",
    "  feature_layer = layers.DenseFeatures(feature_column)\n",
    "  print(feature_layer(example_batch).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1 Columnas Numericas\n",
    "##### 3.2.1.1 Ejemplo: Representación Total Victimas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "totalVictimas = feature_column.numeric_column(\"TOTAL_VICTIMAS\")\n",
    "demo(totalVictimas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.2 Columnas Categóricas\n",
    "##### 3.2.2.1 Ejemplo: Representación Etapa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 9 in ETAPA is inferred from the number of elements in the vocabulary_file Diccionarios/Etapas.txt.\n",
      "WARNING:tensorflow:From /mnt/c/PaperSecuestros/venv/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "WARNING:tensorflow:From /mnt/c/PaperSecuestros/venv/lib/python3.7/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyFileCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "etapa = feature_column.categorical_column_with_vocabulary_file(\n",
    "      'ETAPA', vocabulary_file='Diccionarios/Etapas.txt')\n",
    "\n",
    "etapa_one_hot = feature_column.indicator_column(etapa)\n",
    "demo(etapa_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Construyendo el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:vocabulary_size = 9 in ETAPA is inferred from the number of elements in the vocabulary_file Diccionarios/Etapas.txt.\n",
      "INFO:tensorflow:vocabulary_size = 40 in ANIO_DENUNCIA is inferred from the number of elements in the vocabulary_file Diccionarios/Anios.txt.\n",
      "INFO:tensorflow:vocabulary_size = 40 in ANIO_HECHO is inferred from the number of elements in the vocabulary_file Diccionarios/Anios.txt.\n",
      "INFO:tensorflow:vocabulary_size = 4 in LEY is inferred from the number of elements in the vocabulary_file Diccionarios/Leyes.txt.\n",
      "INFO:tensorflow:vocabulary_size = 34 in DEPARTAMENTO is inferred from the number of elements in the vocabulary_file Diccionarios/Departamentos.txt.\n",
      "INFO:tensorflow:vocabulary_size = 1036 in MUNICIPIO is inferred from the number of elements in the vocabulary_file Diccionarios/Municipios.txt.\n",
      "INFO:tensorflow:vocabulary_size = 45 in SECCIONAL is inferred from the number of elements in the vocabulary_file Diccionarios/Seccionales.txt.\n",
      "INFO:tensorflow:vocabulary_size = 8 in GRUPO_EDAD_VICTIMA is inferred from the number of elements in the vocabulary_file Diccionarios/GrupoEdades.txt.\n"
     ]
    }
   ],
   "source": [
    "feature_columns = []\n",
    "\n",
    "# Columnas Numericas\n",
    "numericas = 'RUPTURA,CONEXO,ESTADO_NOTICIA,PAIS,IMPUTACION,ATIPICIDAD_INEXISTENCIA,ACUSACION,CAPTURA,SEXO_VICTIMA,TOTAL_VICTIMAS,PAIS_NACIMIENTO'.split(',')\n",
    "for header in numericas:\n",
    "    feature_columns.append(feature_column.numeric_column(header))\n",
    "\n",
    "# Columnas Categóricas\n",
    "# ETAPA,ANIO_DENUNCIA,ANIO_ENTRADA,ANIO_HECHO,LEY,DEPARTAMENTO,MUNICIPIO,SECCIONAL,GRUPO_EDAD_VICTIMA\n",
    "\n",
    "diccionarios = 'Diccionarios/{}.txt'\n",
    "categoricas = [\n",
    "    ['ETAPA',diccionarios.format('Etapas')],\n",
    "    ['ANIO_DENUNCIA',diccionarios.format('Anios')],\n",
    "    #['ANIO_ENTRADA',diccionarios.format('Anios')],\n",
    "    ['ANIO_HECHO',diccionarios.format('Anios')],\n",
    "    ['LEY',diccionarios.format('Leyes')],\n",
    "    ['DEPARTAMENTO',diccionarios.format('Departamentos')],\n",
    "    ['MUNICIPIO',diccionarios.format('Municipios')],\n",
    "    ['SECCIONAL',diccionarios.format('Seccionales')],\n",
    "    ['GRUPO_EDAD_VICTIMA',diccionarios.format('GrupoEdades')],\n",
    "]\n",
    "\n",
    "for categoria,diccionario in categoricas:\n",
    "    columna_caracteristica = feature_column.categorical_column_with_vocabulary_file(categoria, vocabulary_file=diccionario)\n",
    "    columna_caracteristica_one_hot = feature_column.indicator_column(columna_caracteristica)\n",
    "    feature_columns.append(columna_caracteristica_one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Capa de Caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Crear, Compilar y Entrenar el Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 800 steps, validate for 200 steps\n",
      "Epoch 1/5\n",
      "800/800 [==============================] - 4s 5ms/step - loss: 0.0998 - accuracy: 0.9629 - val_loss: 0.0845 - val_accuracy: 0.9667\n",
      "Epoch 2/5\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.0698 - accuracy: 0.9744 - val_loss: 0.0756 - val_accuracy: 0.9733\n",
      "Epoch 3/5\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.0637 - accuracy: 0.9769 - val_loss: 0.0851 - val_accuracy: 0.9718\n",
      "Epoch 4/5\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.0599 - accuracy: 0.9789 - val_loss: 0.0702 - val_accuracy: 0.9754\n",
      "Epoch 5/5\n",
      "800/800 [==============================] - 3s 3ms/step - loss: 0.0533 - accuracy: 0.9806 - val_loss: 0.0808 - val_accuracy: 0.9761\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f11063d2b00>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_layer,\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(1)\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_ds,\n",
    "          validation_data=val_ds,\n",
    "          epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 0s 2ms/step - loss: 0.0775 - accuracy: 0.9759\n",
      "Accuracy 0.97585386\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
